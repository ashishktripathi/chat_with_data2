import os
#from langchain_community.chat_models import AzureChatOpenAI
from langchain_openai import AzureChatOpenAI
from langchain_community.utilities.sql_database import SQLDatabase
from langchain.chains import create_sql_query_chain
from utils.load_env import load_environment
from sqlalchemy import text
import pandas as pd 


load_environment()


db_uri = (
    f"mssql+pyodbc://{os.environ['SQL_USERNAME']}:{os.environ['SQL_PASSWORD']}"
    f"@{os.environ['SQL_SERVER']}/{os.environ['SQL_DATABASE']}?"
    "driver=ODBC+Driver+18+for+SQL+Server"
)
print("Connecting to DB with URI:")
print(db_uri)
db = SQLDatabase.from_uri(db_uri)

from langchain_openai import AzureChatOpenAI

llm = AzureChatOpenAI(
    azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
    api_key=os.environ["AZURE_OPENAI_API_KEY"],
    deployment_name=os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"],
    api_version="2023-03-15-preview",
    timeout=15,
)

print("‚úÖ Testing LLM...")
res = llm.invoke("Say hello in one word.")
print(res)

sql_chain = create_sql_query_chain(llm, db)

print("üîç Tables:", db.get_usable_table_names())
print("üìã Schema:")
print(db.get_table_info())

import time

# def ask_db(question):
#     print(f"üß† Asking: {question}")
#     start = time.time()
#     result = sql_chain.invoke({"question": question})
#     print(f"‚úÖ Response in {round(time.time() - start, 2)}s")
#     return result
# def ask_db(question):
#     print(f"\nüß† Asking: {question}")
#     llm_output = sql_chain.invoke({"question": question})
#     print(f"üí° SQL generated by LLM:\n{llm_output}")

#     # Extract the actual SQL query
#     if "SQLQuery:" in llm_output:
#         sql_query = llm_output.split("SQLQuery:")[1].strip()
#     else:
#         sql_query = llm_output.strip()

#     # Run the query
#     with db._engine.connect() as connection:
#         #result = connection.execute(sql_query)
#         result = connection.execute(text(sql_query))
#         rows = result.fetchall()

#         if not rows:
#             return "No results found."

#         return "\n".join(str(row) for row in rows)

def ask_db(question):
    print(f"\nüß† Asking: {question}")
    llm_output = sql_chain.invoke({"question": question})
    print(f"üí° SQL generated by LLM:\n{llm_output}")

    # Extract SQL from the output
    if "SQLQuery:" in llm_output:
        sql_query = llm_output.split("SQLQuery:")[1].strip()
    else:
        sql_query = llm_output.strip()

    try:
        with db._engine.connect() as connection:
            #result = connection.execute(sql_query)
            result = connection.execute(text(sql_query))
            rows = result.fetchall()
            columns = result.keys()
            df = pd.DataFrame(rows, columns=columns)
    except Exception as e:
        return f"‚ö†Ô∏è Error: {str(e)}"

    return {
        "sql": sql_query,
        "result": df if not df.empty else "No results found.",
        "explanation": f"This SQL query was generated based on your question: _{question}_"
    }
    
    
if __name__ == "__main__":
    question = "How many rows are in the Sales table?"
    result = ask_db(question)
    print("Answer is :", result)

